{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3853d0e-9213-4a47-b892-2e1b571946cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>1867983</td><td>99.8</td><td>3583742</td><td>191.4</td><td>2665171</td><td>142.4</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>3312209</td><td>25.3</td><td>8388608</td><td> 64.0</td><td>6045938</td><td> 46.2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells & 1867983 & 99.8 & 3583742 & 191.4 & 2665171 & 142.4\\\\\n",
       "\tVcells & 3312209 & 25.3 & 8388608 &  64.0 & 6045938 &  46.2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells | 1867983 | 99.8 | 3583742 | 191.4 | 2665171 | 142.4 |\n",
       "| Vcells | 3312209 | 25.3 | 8388608 |  64.0 | 6045938 |  46.2 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb)  max used (Mb) \n",
       "Ncells 1867983 99.8 3583742    191.4 2665171  142.4\n",
       "Vcells 3312209 25.3 8388608     64.0 6045938   46.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Necesita para correr en Google Cloud\n",
    "# 256 GB de memoria RAM\n",
    "# 256 GB de espacio en el disco local\n",
    "#   8 vCPU\n",
    "\n",
    "\n",
    "#limpio la memoria\n",
    "rm( list=ls() )  #remove all objects\n",
    "gc()             #garbage collection\n",
    "\n",
    "require(\"data.table\")\n",
    "require(\"Rcpp\")\n",
    "\n",
    "require(\"ranger\")\n",
    "require(\"randomForest\")  #solo se usa para imputar nulos\n",
    "\n",
    "require(\"lightgbm\")\n",
    "\n",
    "\n",
    "#Parametros del script\n",
    "PARAM  <- list()\n",
    "PARAM$experimento <- \"FE_Manual_3lags\"\n",
    "\n",
    "PARAM$exp_input  <- \"DataDrift_Deflacion\"\n",
    "\n",
    "PARAM$lag1  <- TRUE\n",
    "PARAM$lag2  <- TRUE\n",
    "PARAM$Tendencias  <- TRUE\n",
    "PARAM$RandomForest  <- FALSE          #No se puede poner en TRUE para la entrega oficial de la Tercera Competencia\n",
    "PARAM$CanaritosAsesinos  <- TRUE\n",
    "# FIN Parametros del script\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "options(error = function() { \n",
    "  traceback(20); \n",
    "  options(error = NULL); \n",
    "  stop(\"exiting after script error\") \n",
    "})\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#se calculan para los 6 meses previos el minimo, maximo y tendencia calculada con cuadrados minimos\n",
    "#la formula de calculo de la tendencia puede verse en https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.04%3A_The_Least_Squares_Regression_Line\n",
    "#para la maxíma velocidad esta funcion esta escrita en lenguaje C, y no en la porqueria de R o Python\n",
    "\n",
    "cppFunction('NumericVector fhistC(NumericVector pcolumna, IntegerVector pdesde ) \n",
    "{\n",
    "  /* Aqui se cargan los valores para la regresion */\n",
    "  double  x[100] ;\n",
    "  double  y[100] ;\n",
    "  int n = pcolumna.size();\n",
    "  NumericVector out( 5*n );\n",
    "  for(int i = 0; i < n; i++)\n",
    "  {\n",
    "    //lag\n",
    "    if( pdesde[i]-1 < i )  out[ i + 4*n ]  =  pcolumna[i-1] ;\n",
    "    else                   out[ i + 4*n ]  =  NA_REAL ;\n",
    "    int  libre    = 0 ;\n",
    "    int  xvalor   = 1 ;\n",
    "    for( int j= pdesde[i]-1;  j<=i; j++ )\n",
    "    {\n",
    "       double a = pcolumna[j] ;\n",
    "       if( !R_IsNA( a ) ) \n",
    "       {\n",
    "          y[ libre ]= a ;\n",
    "          x[ libre ]= xvalor ;\n",
    "          libre++ ;\n",
    "       }\n",
    "       xvalor++ ;\n",
    "    }\n",
    "    /* Si hay al menos dos valores */\n",
    "    if( libre > 1 )\n",
    "    {\n",
    "      double  xsum  = x[0] ;\n",
    "      double  ysum  = y[0] ;\n",
    "      double  xysum = xsum * ysum ;\n",
    "      double  xxsum = xsum * xsum ;\n",
    "      double  vmin  = y[0] ;\n",
    "      double  vmax  = y[0] ;\n",
    "      for( int h=1; h<libre; h++)\n",
    "      { \n",
    "        xsum  += x[h] ;\n",
    "        ysum  += y[h] ; \n",
    "        xysum += x[h]*y[h] ;\n",
    "        xxsum += x[h]*x[h] ;\n",
    "        if( y[h] < vmin )  vmin = y[h] ;\n",
    "        if( y[h] > vmax )  vmax = y[h] ;\n",
    "      }\n",
    "      out[ i ]  =  (libre*xysum - xsum*ysum)/(libre*xxsum -xsum*xsum) ;\n",
    "      out[ i + n ]    =  vmin ;\n",
    "      out[ i + 2*n ]  =  vmax ;\n",
    "      out[ i + 3*n ]  =  ysum / libre ;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "      out[ i       ]  =  NA_REAL ; \n",
    "      out[ i + n   ]  =  NA_REAL ;\n",
    "      out[ i + 2*n ]  =  NA_REAL ;\n",
    "      out[ i + 3*n ]  =  NA_REAL ;\n",
    "    }\n",
    "  }\n",
    "  return  out;\n",
    "}')\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#calcula la tendencia de las variables cols de los ultimos 6 meses\n",
    "#la tendencia es la pendiente de la recta que ajusta por cuadrados minimos\n",
    "#La funcionalidad de ratioavg es autoria de  Daiana Sparta,  UAustral  2021\n",
    "\n",
    "TendenciaYmuchomas  <- function( dataset, cols, ventana=6, tendencia=TRUE, minimo=TRUE, maximo=TRUE, promedio=TRUE, \n",
    "                                 ratioavg=FALSE, ratiomax=FALSE)\n",
    "{\n",
    "  gc()\n",
    "  #Esta es la cantidad de meses que utilizo para la historia\n",
    "  ventana_regresion  <- ventana\n",
    "\n",
    "  last  <- nrow( dataset )\n",
    "\n",
    "  #creo el vector_desde que indica cada ventana\n",
    "  #de esta forma se acelera el procesamiento ya que lo hago una sola vez\n",
    "  vector_ids   <- dataset$numero_de_cliente\n",
    "\n",
    "  vector_desde  <- seq( -ventana_regresion+2,  nrow(dataset)-ventana_regresion+1 )\n",
    "  vector_desde[ 1:ventana_regresion ]  <-  1\n",
    "\n",
    "  for( i in 2:last )  if( vector_ids[ i-1 ] !=  vector_ids[ i ] ) {  vector_desde[i] <-  i }\n",
    "  for( i in 2:last )  if( vector_desde[i] < vector_desde[i-1] )  {  vector_desde[i] <-  vector_desde[i-1] }\n",
    "\n",
    "  for(  campo  in   cols )\n",
    "  {\n",
    "    nueva_col     <- fhistC( dataset[ , get(campo) ], vector_desde ) \n",
    "\n",
    "    if(tendencia)  dataset[ , paste0( campo, \"_tend\", ventana) := nueva_col[ (0*last +1):(1*last) ]  ]\n",
    "    if(minimo)     dataset[ , paste0( campo, \"_min\", ventana)  := nueva_col[ (1*last +1):(2*last) ]  ]\n",
    "    if(maximo)     dataset[ , paste0( campo, \"_max\", ventana)  := nueva_col[ (2*last +1):(3*last) ]  ]\n",
    "    if(promedio)   dataset[ , paste0( campo, \"_avg\", ventana)  := nueva_col[ (3*last +1):(4*last) ]  ]\n",
    "    if(ratioavg)   dataset[ , paste0( campo, \"_ratioavg\", ventana)  := get(campo) /nueva_col[ (3*last +1):(4*last) ]  ]\n",
    "    if(ratiomax)   dataset[ , paste0( campo, \"_ratiomax\", ventana)  := get(campo) /nueva_col[ (2*last +1):(3*last) ]  ]\n",
    "  }\n",
    "\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "#agrega al dataset nuevas variables {0,1} que provienen de las hojas de un Random Forest\n",
    "\n",
    "AgregaVarRandomForest  <- function( num.trees, max.depth, min.node.size, mtry)\n",
    "{\n",
    "  gc()\n",
    "  dataset[ , clase01:= ifelse( clase_ternaria==\"CONTINUA\", 0, 1 ) ]\n",
    "\n",
    "  campos_buenos  <- setdiff( colnames(dataset), c(\"clase_ternaria\" ) )\n",
    "\n",
    "  dataset_rf  <- copy( dataset[ , campos_buenos, with=FALSE] )\n",
    "  azar  <- runif( nrow(dataset_rf) )\n",
    "  dataset_rf[ , entrenamiento := as.integer( foto_mes>= 202101 &  foto_mes<= 202103 & ( clase01==1 | azar < 0.10 )) ]\n",
    "\n",
    "  #imputo los nulos, ya que ranger no acepta nulos\n",
    "  #Leo Breiman, ¿por que le temias a los nulos?\n",
    "  dataset_rf  <- na.roughfix( dataset_rf )\n",
    "\n",
    "  campos_buenos  <- setdiff( colnames(dataset_rf), c(\"clase_ternaria\",\"entrenamiento\" ) )\n",
    "  modelo  <- ranger( formula= \"clase01 ~ .\",\n",
    "                     data=  dataset_rf[ entrenamiento==1L, campos_buenos, with=FALSE  ] ,\n",
    "                     classification= TRUE,\n",
    "                     probability=   FALSE,\n",
    "                     num.trees=     num.trees,\n",
    "                     max.depth=     max.depth,\n",
    "                     min.node.size= min.node.size,\n",
    "                     mtry=          mtry\n",
    "                   )\n",
    "\n",
    "  rfhojas  <- predict( object= modelo, \n",
    "                       data= dataset_rf[ , campos_buenos, with=FALSE ],\n",
    "                       predict.all= TRUE,    #entrega la prediccion de cada arbol\n",
    "                       type= \"terminalNodes\" #entrega el numero de NODO el arbol\n",
    "                     )\n",
    "\n",
    "  for( arbol in 1:num.trees )\n",
    "  {\n",
    "    hojas_arbol  <- unique(  rfhojas$predictions[  , arbol  ] )\n",
    "\n",
    "    for( pos in 1:length(hojas_arbol) )\n",
    "    {\n",
    "      nodo_id  <- hojas_arbol[ pos ]  #el numero de nodo de la hoja, estan salteados\n",
    "      dataset[  ,  paste0( \"rf_\", sprintf( \"%03d\", arbol ), \"_\", sprintf( \"%03d\", nodo_id ) ) := 0L ]\n",
    "\n",
    "      dataset[ which( rfhojas$predictions[ , arbol] == nodo_id ,  ), \n",
    "               paste0( \"rf_\", sprintf( \"%03d\", arbol ), \"_\", sprintf( \"%03d\", nodo_id ) ) := 1L ]\n",
    "    }\n",
    "  }\n",
    "\n",
    "  rm( dataset_rf )\n",
    "  dataset[ , clase01 := NULL ]\n",
    "\n",
    "  gc()\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "VPOS_CORTE  <- c()\n",
    "\n",
    "fganancia_lgbm_meseta  <- function(probs, datos) \n",
    "{\n",
    "  vlabels  <- get_field(datos, \"label\")\n",
    "  vpesos   <- get_field(datos, \"weight\")\n",
    "\n",
    "  tbl  <- as.data.table( list( \"prob\"=probs, \"gan\"= ifelse( vlabels==1 & vpesos > 1, 78000, -2000 ) ) )\n",
    "\n",
    "  setorder( tbl, -prob )\n",
    "  tbl[ , posicion := .I ]\n",
    "  tbl[ , gan_acum :=  cumsum( gan ) ]\n",
    "  setorder( tbl, -gan_acum )   #voy por la meseta\n",
    "\n",
    "  gan  <- mean( tbl[ 1:500,  gan_acum] )  #meseta de tamaño 500\n",
    "\n",
    "  pos_meseta  <- tbl[ 1:500,  median(posicion)]\n",
    "  VPOS_CORTE  <<- c( VPOS_CORTE, pos_meseta )\n",
    "\n",
    "  return( list( \"name\"= \"ganancia\", \n",
    "                \"value\"=  gan,\n",
    "                \"higher_better\"= TRUE ) )\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "#Elimina del dataset las variables que estan por debajo de la capa geologica de canaritos\n",
    "#se llama varias veces, luego de agregar muchas variables nuevas, para ir reduciendo la cantidad de variables\n",
    "# y así hacer lugar a nuevas variables importantes\n",
    "\n",
    "GVEZ <- 1 \n",
    "\n",
    "CanaritosAsesinos  <- function( canaritos_ratio=0.2 )\n",
    "{\n",
    "  gc()\n",
    "  dataset[ , clase01:= ifelse( clase_ternaria==\"CONTINUA\", 0, 1 ) ]\n",
    "\n",
    "  for( i  in 1:(ncol(dataset)*canaritos_ratio))  dataset[ , paste0(\"canarito\", i ) :=  runif( nrow(dataset))]\n",
    "\n",
    "  campos_buenos  <- setdiff( colnames(dataset), c(\"clase_ternaria\",\"clase01\", \"foto_mes\" ) )\n",
    "\n",
    "  azar  <- runif( nrow(dataset) )\n",
    "  dataset[ , entrenamiento := foto_mes>= 202101 &  foto_mes<= 202103  & ( clase01==1 | azar < 0.10 ) ]\n",
    "\n",
    "  dtrain  <- lgb.Dataset( data=    data.matrix(  dataset[ entrenamiento==TRUE, campos_buenos, with=FALSE]),\n",
    "                          label=   dataset[ entrenamiento==TRUE, clase01],\n",
    "                          weight=  dataset[ entrenamiento==TRUE, ifelse(clase_ternaria==\"BAJA+2\", 1.0000001, 1.0)],\n",
    "                          free_raw_data= FALSE\n",
    "                        )\n",
    "\n",
    "  dvalid  <- lgb.Dataset( data=    data.matrix(  dataset[ foto_mes==202105, campos_buenos, with=FALSE]),\n",
    "                          label=   dataset[ foto_mes==202105, clase01],\n",
    "                          weight=  dataset[ foto_mes==202105, ifelse(clase_ternaria==\"BAJA+2\", 1.0000001, 1.0)],\n",
    "                          free_raw_data= FALSE\n",
    "                          )\n",
    "\n",
    "\n",
    "  param <- list( objective= \"binary\",\n",
    "                 metric= \"custom\",\n",
    "                 first_metric_only= TRUE,\n",
    "                 boost_from_average= TRUE,\n",
    "                 feature_pre_filter= FALSE,\n",
    "                 verbosity= -100,\n",
    "                 seed= 999983,\n",
    "                 max_depth=  -1,         # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "                 min_gain_to_split= 0.0, #por ahora, lo dejo fijo\n",
    "                 lambda_l1= 0.0,         #por ahora, lo dejo fijo\n",
    "                 lambda_l2= 0.0,         #por ahora, lo dejo fijo\n",
    "                 max_bin= 31,            #por ahora, lo dejo fijo\n",
    "                 num_iterations= 9999,   #un numero muy grande, lo limita early_stopping_rounds\n",
    "                 force_row_wise= TRUE,    #para que los alumnos no se atemoricen con tantos warning\n",
    "                 learning_rate= 0.065, \n",
    "                 feature_fraction= 1.0,   #lo seteo en 1 para que las primeras variables del dataset no se vean opacadas\n",
    "                 min_data_in_leaf= 260,\n",
    "                 num_leaves= 60,\n",
    "                 early_stopping_rounds= 200 )\n",
    "\n",
    "  modelo  <- lgb.train( data= dtrain,\n",
    "                        valids= list( valid= dvalid ),\n",
    "                        eval= fganancia_lgbm_meseta,\n",
    "                        param= param,\n",
    "                        verbose= -100 )\n",
    "\n",
    "  tb_importancia  <- lgb.importance( model= modelo )\n",
    "  tb_importancia[  , pos := .I ]\n",
    "\n",
    "  fwrite( tb_importancia, \n",
    "          file= paste0( \"impo_\", GVEZ ,\".txt\"),\n",
    "          sep= \"\\t\" )\n",
    "\n",
    "  GVEZ  <<- GVEZ + 1\n",
    "\n",
    "  umbral  <- tb_importancia[ Feature %like% \"canarito\", median(pos) + 2*sd(pos) ]  #Atencion corto en la mediana mas DOS desvios!!\n",
    "\n",
    "  col_utiles  <- tb_importancia[ pos < umbral & !( Feature %like% \"canarito\"),  Feature ]\n",
    "  col_utiles  <-  unique( c( col_utiles,  c(\"numero_de_cliente\",\"foto_mes\",\"clase_ternaria\",\"mes\") ) )\n",
    "  col_inutiles  <- setdiff( colnames(dataset), col_utiles )\n",
    "\n",
    "  dataset[  ,  (col_inutiles) := NULL ]\n",
    "\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------\n",
    "#Aqui empieza el programa\n",
    "\n",
    "setwd( \"~/buckets/b1/\" )\n",
    "\n",
    "#cargo el dataset donde voy a entrenar\n",
    "#esta en la carpeta del exp_input y siempre se llama  dataset.csv.gz\n",
    "dataset_input  <- paste0( \"./exp/\", PARAM$exp_input, \"/dataset.csv.gz\" )\n",
    "dataset  <- fread( dataset_input )\n",
    "\n",
    "\n",
    "\n",
    "#creo la carpeta donde va el experimento\n",
    "dir.create( paste0( \"./exp/\", PARAM$experimento, \"/\"), showWarnings = FALSE )\n",
    "setwd(paste0( \"./exp/\", PARAM$experimento, \"/\"))   #Establezco el Working Directory DEL EXPERIMENTO\n",
    "\n",
    "#--------------------------------------\n",
    "#estas son las columnas a las que se puede agregar lags o media moviles ( todas menos las obvias )\n",
    "cols_lagueables  <- copy(  setdiff( colnames(dataset), c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")  ) )\n",
    "\n",
    "#ordeno el dataset por <numero_de_cliente, foto_mes> para poder hacer lags\n",
    "#  es MUY  importante esta linea\n",
    "setorder( dataset, numero_de_cliente, foto_mes )\n",
    "\n",
    "\n",
    "if( PARAM$lag1 )\n",
    "{\n",
    "  #creo los campos lags de orden 1\n",
    "  dataset[ , paste0( cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"), \n",
    "             by= numero_de_cliente, \n",
    "             .SDcols= cols_lagueables ]\n",
    "\n",
    "  #agrego los delta lags de orden 1\n",
    "  for( vcol in cols_lagueables )\n",
    "  {\n",
    "    dataset[ , paste0(vcol, \"_delta1\") := get(vcol)  - get(paste0( vcol, \"_lag1\"))  ]\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "if( PARAM$lag2 )\n",
    "{\n",
    "  #creo los campos lags de orden 2\n",
    "  dataset[ , paste0( cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"), \n",
    "             by= numero_de_cliente, \n",
    "             .SDcols= cols_lagueables ]\n",
    "\n",
    "  #agrego los delta lags de orden 2\n",
    "  for( vcol in cols_lagueables )\n",
    "  {\n",
    "    dataset[ , paste0(vcol, \"_delta2\") := get(vcol)  - get(paste0( vcol, \"_lag2\"))  ]\n",
    "  }\n",
    "}\n",
    "\n",
    "if( PARAM$lag2 )\n",
    "{\n",
    "  #creo los campos lags de orden 2\n",
    "  dataset[ , paste0( cols_lagueables, \"_lag3\") := shift(.SD, 3, NA, \"lag\"), \n",
    "             by= numero_de_cliente, \n",
    "             .SDcols= cols_lagueables ]\n",
    "\n",
    "  #agrego los delta lags de orden 2\n",
    "  for( vcol in cols_lagueables )\n",
    "  {\n",
    "    dataset[ , paste0(vcol, \"_delta3\") := get(vcol)  - get(paste0( vcol, \"_lag3\"))  ]\n",
    "  }\n",
    "}\n",
    "\n",
    "    \n",
    "#--------------------------------------\n",
    "#agrego las tendencias\n",
    "\n",
    "#ordeno el dataset por <numero_de_cliente, foto_mes> para poder hacer lags\n",
    "#  es MUY  importante esta linea\n",
    "setorder( dataset, numero_de_cliente, foto_mes )\n",
    "\n",
    "if( PARAM$Tendencias )\n",
    "{\n",
    "  TendenciaYmuchomas( dataset, \n",
    "                      cols= cols_lagueables,\n",
    "                      ventana=   6,      # 6 meses de historia\n",
    "                      tendencia= TRUE,\n",
    "                      minimo=    FALSE,\n",
    "                      maximo=    FALSE,\n",
    "                      promedio=  TRUE,\n",
    "                      ratioavg=  FALSE,\n",
    "                      ratiomax=  FALSE  )\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#Agrego variables a partir de las hojas de un Random Forest\n",
    "\n",
    "if( PARAM$RandomForest )\n",
    "{\n",
    "  AgregaVarRandomForest( num.trees = 40,\n",
    "                         max.depth = 5,\n",
    "                         min.node.size = 500,\n",
    "                         mtry = 15 )\n",
    "\n",
    "  gc()\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#Elimino las variables que no son tan importantes en el dataset\n",
    "# with great power comes grest responsability\n",
    "\n",
    "######################## fe custom ################################\n",
    "#######################################################################\n",
    "#Aqui debe usted agregar sus propias nuevas variables\n",
    "  #######################################################################\n",
    "\n",
    "# sumo prestamos\n",
    "dataset[, c_totalprestamos := rowSums( cbind(cprestamos_hipotecarios, cprestamos_prendarios, cprestamos_personales), na.rm=TRUE)] \n",
    "dataset[, m_totalprestamos := rowSums( cbind(mprestamos_hipotecarios, mprestamos_prendarios, mprestamos_personales), na.rm=TRUE)] \n",
    "\n",
    "# sumo playroll\n",
    "dataset[, c_totalpayroll := rowSums(cbind(cpayroll_trx, cpayroll2_trx), na.rm=TRUE)] \n",
    "dataset[, m_totalpayroll := rowSums(cbind(mpayroll, mpayroll2), na.rm=TRUE)] \n",
    "#misma transformacion sobre mpayroll pero sobre la suma\n",
    "dataset[  , m_totalpayroll_sobre_edad  := m_totalpayroll / cliente_edad ]\n",
    "\n",
    "# sumo descuentos\n",
    "dataset[, c_totaldescuentos := rowSums(cbind(ccajeros_propios_descuentos, ctarjeta_visa_descuentos, ctarjeta_master_descuentos), na.rm=TRUE)] \n",
    "dataset[, m_totaldescuentos := rowSums(cbind(mcajeros_propios_descuentos, mtarjeta_visa_descuentos, mtarjeta_master_descuentos), na.rm=TRUE)] \n",
    "\n",
    "# sumo comisiones\n",
    "dataset[, c_totalcomisiones := rowSums(cbind(ccomisiones_otras, ccomisiones_otras), na.rm=TRUE)] \n",
    "dataset[, m_totalcomisiones := rowSums(cbind(mcomisiones_mantenimiento, mcomisiones_otras), na.rm=TRUE)] \n",
    "\n",
    "# sumo saldos en cuentas a la vista\n",
    "dataset[, m_totalctavista := rowSums(cbind(mcuenta_corriente_adicional, mcuenta_corriente, mcaja_ahorro, mcaja_ahorro_adicional, mcaja_ahorro_dolares), na.rm=TRUE)] \n",
    "\n",
    "# sumo todo el dinero que el cliente tiene en el banco\n",
    "dataset[,m_totaldinero := rowSums(cbind( m_totalctavista,  minversion1_pesos,  minversion1_dolares,  minversion2,  mplazo_fijo_dolares), na.rm=TRUE)]\n",
    "\n",
    "# suma de margenes\n",
    "dataset[,m_totalmargenes := rowSums(cbind(mactivos_margen, mpasivos_margen), na.rm=TRUE)]\n",
    "\n",
    "\n",
    "# total de transacciones mensuales por todos los canales y por todos los instrumentos\n",
    "dataset[, c_totaltransac := rowSums(cbind ( ctarjeta_debito_transacciones,  ctarjeta_visa_transacciones, ctarjeta_master_transacciones,\n",
    "                                          ccuenta_debitos_automaticos,  ctarjeta_visa_debitos_automaticos,  ctarjeta_master_debitos_automaticos,\n",
    "                                          cpagodeservicios,  cpagomiscuentas,  cforex_buy,  cforex_sell,  ctransferencias_recibidas,\n",
    "                                          ctransferencias_emitidas,  cextraccion_autoservicio,  ccheques_depositados,  ccheques_emitidos,\n",
    "                                          ccheques_depositados_rechazados, ccheques_emitidos_rechazados,\n",
    "                                          ccallcenter_transacciones,  chomebanking_transacciones,  ccajas_transacciones,  ccajas_consultas,\n",
    "                                          ccajas_depositos,  ccajas_extracciones,  ccajas_otras, catm_trx,  catm_trx_other, cmobile_app_trx),na.rm=TRUE)]\n",
    "\n",
    "# monto involucrado en todas las transacciones\n",
    "dataset[, m_totaltransac := rowSums(cbind (mautoservicio, mtarjeta_visa_consumo, mtarjeta_master_consumo, mcuenta_debitos_automaticos,\n",
    "                                          mttarjeta_visa_debitos_automaticos, mttarjeta_master_debitos_automaticos, mpagodeservicios,\n",
    "                                          mpagomiscuentas, mforex_buy, mforex_sell, mtransferencias_recibidas, mtransferencias_emitidas,\n",
    "                                          mextraccion_autoservicio, mcheques_depositados, mcheques_emitidos, mcheques_depositados_rechazados,\n",
    "                                          mcheques_emitidos_rechazados, matm), na.rm=TRUE)]\n",
    "\n",
    "# suma seguros\n",
    "dataset[, c_totalseguros := rowSums(cbind( cseguro_vida,  cseguro_auto,  cseguro_vivienda, cseguro_accidentes_personales), na.rm=TRUE)]\n",
    "\n",
    "# ratio entre prestamos y haberes. Si haberes cero -> entre prestamos y saldos cuentas a la vista\n",
    "dataset[, mr_prestamos := ifelse(m_totalpayroll==0, ifelse(m_totalctavista<=0,0,m_totalprestamos/m_totalctavista), m_totalprestamos/m_totalpayroll)] \n",
    "\n",
    "# ratio entre limite compra total y haberes. Si cero -> entre limite y saldo cuentas\n",
    "dataset[, mr_limitecompra := ifelse(m_totalpayroll==0, ifelse(m_totalctavista<=0,0,vm_mlimitecompra/m_totalctavista), vm_mlimitecompra/m_totalpayroll)] \n",
    "\n",
    "# ratio entre comisiones y descuentos \n",
    "dataset[, mr_desc_com := ifelse(m_totalcomisiones==0,9999 ,m_totaldescuentos / m_totalcomisiones)]\n",
    "\n",
    "\n",
    "if( PARAM$CanaritosAsesinos )\n",
    "{\n",
    "  ncol( dataset )\n",
    "  CanaritosAsesinos( canaritos_ratio = 0.12 )\n",
    "  ncol( dataset )\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#grabo el dataset\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "fwrite( dataset,\n",
    "        \"dataset.csv.gz\",\n",
    "        logical01= TRUE,\n",
    "        sep= \",\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21804527-0a4f-4f42-b8f1-0e35ada585a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
